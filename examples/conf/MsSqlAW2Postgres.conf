/**
 * This is a standalone, i.e. not using the template, example config file for migrating the sample
 * AdventureWorks database from MS SQL Server to Postgres
 * See https://github.com/Microsoft/sql-server-samples/tree/master/samples/databases/adventure-works
 */
{
    /**
     * Migration project name
     */
     name : "AdventureWorks"

    ,information_schema : {

        /**
         * The information schema query determines which tables and/or views will be migrated.
         *
         * In MS SQL Server, the user must have the 'VIEW DEFINITION' permission in order to
         * view column defaults and computed values.  You can add it with the following command
         * in the source database:
         *
         *    GRANT VIEW DEFINITION TO <user>;
         */
        query : "
            SELECT   C.TABLE_SCHEMA
                    ,C.TABLE_NAME
                    ,C.COLUMN_NAME
                    ,C.ORDINAL_POSITION
                    ,C.IS_NULLABLE
                    ,C.DATA_TYPE
                    ,C.CHARACTER_MAXIMUM_LENGTH
                    ,C.NUMERIC_PRECISION
                    ,C.NUMERIC_PRECISION_RADIX
                    ,C.COLUMN_DEFAULT
                    ,COLUMNPROPERTY(OBJECT_ID(C.TABLE_SCHEMA + '.' + C.TABLE_NAME), C.COLUMN_NAME, 'IsIdentity') AS IS_IDENTITY
                    ,COLUMNPROPERTY(OBJECT_ID(C.TABLE_SCHEMA + '.' + C.TABLE_NAME), C.COLUMN_NAME, 'IsComputed') AS IS_COMPUTED
                    ,SCC.DEFINITION AS COLUMN_DEFINITION
            FROM    INFORMATION_SCHEMA.COLUMNS C
                JOIN INFORMATION_SCHEMA.TABLES T ON
                        T.TABLE_SCHEMA      = C.TABLE_SCHEMA
                    AND T.TABLE_NAME        = C.TABLE_NAME
                    AND T.TABLE_CATALOG     = C.TABLE_CATALOG
                LEFT JOIN sys.columns SC ON
                        SC.object_id        = OBJECT_ID(C.TABLE_SCHEMA + '.' + C.TABLE_NAME)
                    AND SC.name             = C.COLUMN_NAME
                LEFT JOIN sys.computed_columns SCC ON
                        SCC.object_id       = OBJECT_ID(C.TABLE_SCHEMA + '.' + C.TABLE_NAME)
                    AND SCC.name            = C.COLUMN_NAME
            WHERE    T.TABLE_CATALOG        = 'AdventureWorks'
                 AND T.TABLE_TYPE           = 'BASE TABLE'
            --   AND T.TABLE_NAME  NOT LIKE 'exclude-pattern'
            --   AND C.COLUMN_NAME NOT LIKE 'exclude-pattern'
                 AND T.TABLE_NAME NOT IN ('dtproperties')
            ORDER BY T.TABLE_SCHEMA, T.TABLE_NAME, C.ORDINAL_POSITION;
            "
    }

    /**
     * The names of the connections that will be used as source (copy from) and target (copy to).
     * The keys of source and target must appear in the connections segment of the config.
     */
    ,source : "mssql"
    ,target : "postgres"

    /**
     * Defines the available database connections.  Each connection must
     * have a connectionString key.  Other keys are optional and will be
     * added to the Properties object when connecting to the database.
     */
    ,connections : {
         mssql : {
              connectionString : "jdbc:sqlserver://localhost:1433"
             ,user             : "%connections.mssql.user%"
             ,password         : "%connections.mssql.password%"
             ,databaseName     : "AdventureWorks"
        }
        ,postgres : {
              connectionString : "jdbc:postgresql://localhost:5432/adventure_works"
             ,user             : "postgres"
             ,password         : ""
        }
    }

    /**
     * Mappings for schema names from source to target, e.g. HumanResources -> hr
     */
    ,schema_mapping : {
         dbo            : "public"
        ,HumanResources : "hr"
    }

    /**
     * Mappings for table names from source to target, e.g. HumanResources -> hr
     * runs before table_transform
     */
    ,table_mapping : {
         HumanResources : "hr"
    }

    /**
     * Mappings for column names in case the source db has keyword names like "group" or
     * "primary", or has a space that we want to remove.
     * runs before column_transform
     */
    ,column_mapping : {
         "Database Version" : "db_version"
        ,group              : "group_name"
        ,primary            : "is_primary"
    }

    /**
     * Specify whether to transform the table and/or column names.  Available transforms are:
     *   lower_case          - transforms MyTableName to mytablename
     *   upper_case          - transforms MyTableName to MYTABLENAME
     *   camel_to_snake_case - transforms MyTableName to my_table_name
     */
    ,table_transform  : "camel_to_snake_case"
    ,column_transform : "camel_to_snake_case"

    /**
     * DDL (create objects) command settings
     */
    ,ddl : {

        /**
         * When true, a DROP SCHEMA IF EXISTS will be added at the top of the DDL script
         */
        drop_schema : false

        /**
         * SQL type mapping for DDL, e.g. map ntext -> text
         */
        ,sql_type_mapping : {
    //       bigint                : ""
             bigint_auto_increment : "bigserial"
    //      ,bigint_identity       : "bigint generated always as identity"
            ,bigint_identity       : "bigint generated by default as identity"
            ,bit                   : "boolean"
            ,char                  : "varchar"
    //      ,date                  : ""
            ,datetime              : "timestamptz"
            ,float                 : "real"
            ,geography             : "text"
            ,hierarchyid           : "text"         // TODO: ltree ?
    //      ,int                   : ""
            ,int_auto_increment    : "serial"
    //      ,int_identity          : "int generated always as identity"
            ,int_identity          : "int generated by default as identity"
            ,money                 : "numeric"
            ,ntext                 : "text"
            ,nvarchar              : "varchar"
            ,nvarchar_invalid      : "text"
    //      ,real                  : ""
            ,smalldatetime         : "timestamptz"
            ,smallint              : "int"
            ,smallmoney            : "numeric"
    //      ,text                  : ""
            ,tinyint               : "int"
            ,uniqueidentifier      : "char(36)"
            ,varbinary             : "bytea"
    //      ,varchar               : "text"
            ,varchar_invalid       : "text"
            ,xml                   : "text"         // TODO: convert to xml?
        }

        /**
         * Regular Expressions that will be used to convert defaults, e.g. from getdate() to current_timestamp
         * Only matches will be used in DDL without being commented out. '\' characters must be escaped.
         */
        ,column_default_replace : {
             "^\\(+(0|1)\\)+$"              : "$1"                  // (0), ((0)), (1), ((1))
            ,"^\\(+(\\d+\\.?(\\d+)?)\\)+$"  : "$1"                  // ('123'), ('123.45')
            ,"^\\(+('.*?')\\)+$"            : "$1"                  // ('abc'), ('Abc Def')
            ,"^\\(+(getdate\\(\\)\\))+$"    : "current_timestamp"   // (getdate())
            ,"^\\(+(newid\\(\\)\\))+$"      : "gen_random_uuid()"   // (newid())
        }
    }

    /**
     * DML command settings (copy data)
     */
    ,dml : {

        /**
         * rollback - roll back the current transaction, default
         * // TODO: continue - ignore the error
         * // TODO: abort    - aborts the whole operation
         */
        on_error : "rollback"

        /**
            JDBC type mapping used for DML, e.g. longnvarchar -> longvarchar
            see https://docs.oracle.com/javase/8/docs/api/java/sql/JDBCType.html
            and https://docs.oracle.com/javase/8/docs/api/constant-values.html#java.sql.Types.ARRAY
        */
        ,jdbc_type_mapping : {
             longnvarchar          : "longvarchar"      // MSSQL ntext
            ,nchar                 : "char"
            ,nclob                 : "clob"
            ,nvarchar              : "varchar"
        }

        /**
         * Wrap columns with prefix and suffix in case a column name is a keyword, e.g. [key]
         */
        ,source_column_quote_prefix : "["
        ,source_column_quote_suffix : "]"
    }
}
